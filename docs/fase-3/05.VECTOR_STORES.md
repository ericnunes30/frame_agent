# Integração com Vector Stores\n\n## Visão Geral\n\nA integração com vector stores permite que os agentes acessem e recuperem informações de grandes conjuntos de dados não estruturados, utilizando técnicas de Retrieval-Augmented Generation (RAG). Isso amplia significativamente as capacidades dos agentes, permitindo que eles trabalhem com conhecimento extenso e atualizado.\n\n## Conceito de Vector Stores\n\nVector stores são sistemas especializados em armazenar e buscar embeddings vetoriais de textos. Eles permitem:\n- Indexação de documentos e conteúdo\n- Busca semântica de informações relevantes\n- Recuperação eficiente de conhecimento\n\n## Interface de Vector Store\n\n```typescript\ninterface VectorStoreConfig {\n  type: 'pinecone' | 'weaviate' | 'chroma' | 'qdrant' | 'milvus';\n  apiKey?: string;\n  url?: string;\n  indexName: string;\n  dimension: number;\n  namespace?: string;\n  batchSize?: number;\n  similarityMetric?: 'cosine' | 'euclidean' | 'dotproduct';\n}\n\ninterface VectorStoreManager {\n  connect(config: VectorStoreConfig): Promise<void>;\n  disconnect(): Promise<void>;\n  index(documents: DocumentInput[], options?: IndexOptions): Promise<IndexResult>;\n  search(query: string | number[], options?: SearchOptions): Promise<SearchResult[]>;\n  delete(filter: DeleteFilter): Promise<DeleteResult>;\n  update(documentId: string, updates: Partial<DocumentInput>): Promise<void>;\n  getDocument(documentId: string): Promise<Document | null>;\n  listIndexes(): Promise<string[]>;\n  createIndex(indexName: string, options: CreateIndexOptions): Promise<void>;\n  deleteIndex(indexName: string): Promise<void>;\n}\n\ninterface DocumentInput {\n  id: string;\n  content: string;\n  metadata?: Record<string, any>;\n  embedding?: number[];\n}\n\ninterface Document extends DocumentInput {\n  createdAt: Date;\n  updatedAt: Date;\n}\n\ninterface SearchResult {\n  document: Document;\n  score: number;\n  metadata: Record<string, any>;\n}\n\ninterface IndexOptions {\n  batchSize?: number;\n  preprocess?: (doc: DocumentInput) => DocumentInput;\n  generateEmbeddings?: boolean;\n}\n\ninterface SearchOptions {\n  topK?: number;\n  filter?: Record<string, any>;\n  includeMetadata?: boolean;\n  includeValues?: boolean;\n  namespace?: string;\n}\n\ninterface DeleteFilter {\n  ids?: string[];\n  filter?: Record<string, any>;\n  namespace?: string;\n}\n\ninterface CreateIndexOptions {\n  dimension: number;\n  metric: string;\n  podType?: string;\n  replicas?: number;\n  shards?: number;\n}\n```\n\n## Implementações de Vector Stores\n\n### 1. Pinecone Integration\n\n```typescript\nclass PineconeVectorStore implements VectorStoreManager {\n  private pinecone: PineconeClient | null = null;\n  private index: PineconeIndex | null = null;\n  private config: VectorStoreConfig | null = null;\n  private embedder: TextEmbedder;\n  \n  constructor(embedder: TextEmbedder) {\n    this.embedder = embedder;\n  }\n  \n  async connect(config: VectorStoreConfig): Promise<void> {\n    this.config = config;\n    \n    this.pinecone = new PineconeClient();\n    await this.pinecone.init({\n      apiKey: config.apiKey!,\n      environment: config.url || 'us-west1-gcp'\n    });\n    \n    this.index = this.pinecone.Index(config.indexName);\n  }\n  \n  async index(documents: DocumentInput[], options: IndexOptions = {}): Promise<IndexResult> {\n    if (!this.index) {\n      throw new Error('Vector store não conectado');\n    }\n    \n    const batchSize = options.batchSize || this.config?.batchSize || 100;\n    const results: IndexResult = {\n      indexedCount: 0,\n      failedCount: 0,\n      errors: []\n    };\n    \n    for (let i = 0; i < documents.length; i += batchSize) {\n      const batch = documents.slice(i, i + batchSize);\n      const processedBatch = await this.processBatch(batch, options);\n      \n      try {\n        await this.index.upsert({\n          upsertRequest: {\n            vectors: processedBatch.map(doc => ({\n              id: doc.id,\n              values: doc.embedding!,\n              metadata: {\n                content: doc.content,\n                ...doc.metadata,\n                createdAt: new Date().toISOString()\n              }\n            })),\n            namespace: this.config?.namespace\n          }\n        });\n        \n        results.indexedCount += processedBatch.length;\n      } catch (error) {\n        results.failedCount += processedBatch.length;\n        results.errors.push({\n          batchStart: i,\n          batchEnd: Math.min(i + batchSize - 1, documents.length - 1),\n          error: error instanceof Error ? error.message : String(error)\n        });\n      }\n    }\n    \n    return results;\n  }\n  \n  async search(query: string | number[], options: SearchOptions = {}): Promise<SearchResult[]> {\n    if (!this.index) {\n      throw new Error('Vector store não conectado');\n    }\n    \n    const queryVector = typeof query === 'string' \n      ? await this.embedder.embed(query) \n      : query;\n    \n    const searchOptions: PineconeQueryRequest = {\n      vector: queryVector,\n      topK: options.topK || 10,\n      includeMetadata: options.includeMetadata !== false,\n      includeValues: options.includeValues || false,\n      namespace: options.namespace || this.config?.namespace\n    };\n    \n    if (options.filter) {\n      searchOptions.filter = options.filter;\n    }\n    \n    const response = await this.index.query(searchOptions);\n    \n    return response.matches?.map(match => ({\n      document: {\n        id: match.id,\n        content: match.metadata?.content || '',\n        metadata: match.metadata || {},\n        embedding: match.values,\n        createdAt: new Date(),\n        updatedAt: new Date()\n      },\n      score: match.score || 0,\n      metadata: match.metadata || {}\n    })) || [];\n  }\n  \n  async delete(filter: DeleteFilter): Promise<DeleteResult> {\n    if (!this.index) {\n      throw new Error('Vector store não conectado');\n    }\n    \n    const deleteRequest: PineconeDeleteRequest = {\n      namespace: filter.namespace || this.config?.namespace\n    };\n    \n    if (filter.ids && filter.ids.length > 0) {\n      deleteRequest.ids = filter.ids;\n    }\n    \n    if (filter.filter) {\n      deleteRequest.filter = filter.filter;\n    }\n    \n    await this.index.delete1(deleteRequest);\n    \n    return {\n      deletedCount: filter.ids?.length || 0, // Pinecone não retorna contagem exata\n      success: true\n    };\n  }\n  \n  private async processBatch(batch: DocumentInput[], options: IndexOptions): Promise<DocumentInput[]> {\n    let processed = batch;\n    \n    // Pré-processamento\n    if (options.preprocess) {\n      processed = processed.map(options.preprocess);\n    }\n    \n    // Geração de embeddings\n    if (options.generateEmbeddings !== false) {\n      const contents = processed.map(doc => doc.content);\n      const embeddings = await this.embedder.embedBatch(contents);\n      \n      processed = processed.map((doc, index) => ({\n        ...doc,\n        embedding: embeddings[index]\n      }));\n    }\n    \n    return processed;\n  }\n}\n```\n\n### 2. Chroma Integration\n\n```typescript\nclass ChromaVectorStore implements VectorStoreManager {\n  private client: ChromaClient | null = null;\n  private collection: Collection | null = null;\n  private config: VectorStoreConfig | null = null;\n  private embedder: TextEmbedder;\n  \n  constructor(embedder: TextEmbedder) {\n    this.embedder = embedder;\n  }\n  \n  async connect(config: VectorStoreConfig): Promise<void> {\n    this.config = config;\n    \n    this.client = new ChromaClient({\n      baseUrl: config.url || 'http://localhost:8000'\n    });\n    \n    // Criar ou obter coleção\n    try {\n      this.collection = await this.client.getOrCreateCollection({\n        name: config.indexName,\n        metadata: {\n          dimension: config.dimension\n        }\n      });\n    } catch (error) {\n      // Se a coleção não existir, criar uma nova\n      this.collection = await this.client.createCollection({\n        name: config.indexName,\n        metadata: {\n          dimension: config.dimension\n        }\n      });\n    }\n  }\n  \n  async index(documents: DocumentInput[], options: IndexOptions = {}): Promise<IndexResult> {\n    if (!this.collection) {\n      throw new Error('Vector store não conectado');\n    }\n    \n    const processedDocs = await this.processDocuments(documents, options);\n    \n    const ids = processedDocs.map(doc => doc.id);\n    const embeddings = processedDocs.map(doc => doc.embedding!);\n    const metadatas = processedDocs.map(doc => ({\n      content: doc.content,\n      ...doc.metadata\n    }));\n    const documentsText = processedDocs.map(doc => doc.content);\n    \n    await this.collection.add({\n      ids,\n      embeddings,\n      metadatas,\n      documents: documentsText\n    });\n    \n    return {\n      indexedCount: processedDocs.length,\n      failedCount: 0,\n      errors: []\n    };\n  }\n  \n  async search(query: string | number[], options: SearchOptions = {}): Promise<SearchResult[]> {\n    if (!this.collection) {\n      throw new Error('Vector store não conectado');\n    }\n    \n    const queryVector = typeof query === 'string' \n      ? await this.embedder.embed(query) \n      : query;\n    \n    const results = await this.collection.query({\n      queryEmbeddings: queryVector,\n      nResults: options.topK || 10,\n      where: options.filter\n    });\n    \n    return results.ids[0].map((id: string, index: number) => ({\n      document: {\n        id,\n        content: results.documents[0][index],\n        metadata: results.metadatas[0][index] || {},\n        embedding: results.embeddings[0][index],\n        createdAt: new Date(),\n        updatedAt: new Date()\n      },\n      score: results.distances[0][index],\n      metadata: results.metadatas[0][index] || {}\n    }));\n  }\n  \n  // Outros métodos de implementação similar\n}\n```\n\n## Integração com o Agente\n\n### Extensão da Classe ChatAgent\n\n```typescript\nclass RAGAgent extends ChatAgent {\n  private vectorStores: Map<string, VectorStoreManager> = new Map();\n  private embedder: TextEmbedder;\n  \n  constructor(config: AgentConfig, embedder: TextEmbedder) {\n    super(config);\n    this.embedder = embedder;\n  }\n  \n  async addVectorStore(name: string, config: VectorStoreConfig): Promise<void> {\n    let vectorStore: VectorStoreManager;\n    \n    switch (config.type) {\n      case 'pinecone':\n        vectorStore = new PineconeVectorStore(this.embedder);\n        break;\n      case 'chroma':\n        vectorStore = new ChromaVectorStore(this.embedder);\n        break;\n      case 'weaviate':\n        vectorStore = new WeaviateVectorStore(this.embedder);\n        break;\n      default:\n        throw new Error(`Vector store não suportado: ${config.type}`);\n    }\n    \n    await vectorStore.connect(config);\n    this.vectorStores.set(name, vectorStore);\n  }\n  \n  async indexDocuments(\n    storeName: string, \n    documents: DocumentInput[], \n    options?: IndexOptions\n  ): Promise<IndexResult> {\n    const store = this.vectorStores.get(storeName);\n    if (!store) {\n      throw new Error(`Vector store '${storeName}' não encontrado`);\n    }\n    \n    return await store.index(documents, options);\n  }\n  \n  async searchKnowledge(\n    storeName: string,\n    query: string,\n    options?: SearchOptions\n  ): Promise<SearchResult[]> {\n    const store = this.vectorStores.get(storeName);\n    if (!store) {\n      throw new Error(`Vector store '${storeName}' não encontrado`);\n    }\n    \n    return await store.search(query, options);\n  }\n  \n  async augmentContextWithKnowledge(\n    query: string,\n    storeName?: string\n  ): Promise<string> {\n    const stores = storeName \n      ? [this.vectorStores.get(storeName)].filter(Boolean)\n      : Array.from(this.vectorStores.values());\n    \n    if (stores.length === 0) {\n      return '';\n    }\n    \n    const allResults: SearchResult[] = [];\n    \n    // Buscar em todos os vector stores relevantes\n    for (const store of stores) {\n      const results = await store.search(query, { topK: 3 });\n      allResults.push(...results);\n    }\n    \n    // Ordenar por score e pegar os melhores\n    allResults.sort((a, b) => b.score - a.score);\n    const topResults = allResults.slice(0, 5);\n    \n    // Formatar resultados para contexto\n    return topResults.map(result => \n      `[Documento: ${result.document.id}]\n${result.document.content}`\n    ).join('\\n\\n');\n  }\n  \n  async sendKnowledgeAugmentedMessage(message: string): Promise<string> {\n    // Obter conhecimento relevante\n    const knowledge = await this.augmentContextWithKnowledge(message);\n    \n    // Adicionar conhecimento ao contexto\n    if (knowledge) {\n      this.memoryManager.addMessage({\n        role: 'system',\n        content: `Informação de contexto:\n${knowledge}`\n      });\n    }\n    \n    // Enviar mensagem normalmente\n    return await super.sendMessage(message);\n  }\n}\n```\n\n## Exemplos de Uso\n\n### 1. Configuração e Indexação\n\n```typescript\nconst agent = new RAGAgent({\n  name: \"Pesquisador\",\n  instructions: \"Você é um assistente especializado em pesquisa e análise\",\n  provider: \"openai-generic\"\n}, new OpenAIEmbedder());\n\n// Adicionar vector store\nawait agent.addVectorStore('knowledge-base', {\n  type: 'pinecone',\n  apiKey: process.env.PINECONE_API_KEY,\n  indexName: 'research-knowledge',\n  dimension: 1536\n});\n\n// Indexar documentos\nconst documents: DocumentInput[] = [\n  {\n    id: 'doc-001',\n    content: 'A inteligência artificial é um campo da ciência da computação...',\n    metadata: {\n      source: 'wikipedia',\n      category: 'introducao',\n      language: 'pt'\n    }\n  },\n  {\n    id: 'doc-002',\n    content: 'Machine learning é uma subcategoria da inteligência artificial...',\n    metadata: {\n      source: 'artigo-cientifico',\n      category: 'conceitos',\n      language: 'pt'\n    }\n  }\n];\n\nconst indexResult = await agent.indexDocuments('knowledge-base', documents);\nconsole.log(`Indexados: ${indexResult.indexedCount}, Falhas: ${indexResult.failedCount}`);\n```\n\n### 2. Busca e Uso de Conhecimento\n\n```typescript\n// Buscar conhecimento específico\nconst results = await agent.searchKnowledge('knowledge-base', 'o que é machine learning?');\nconsole.log('Resultados encontrados:', results);\n\n// Enviar mensagem com aumento de contexto\nconst response = await agent.sendKnowledgeAugmentedMessage(\n  'Explique machine learning de forma simples'\n);\nconsole.log('Resposta:', response);\n```\n\n### 3. Agente com Múltiplos Vector Stores\n\n```typescript\nconst agent = new RAGAgent({\n  name: \"Assistente Completo\",\n  instructions: \"Você é um assistente com acesso a múltiplas bases de conhecimento\",\n  provider: \"openai-generic\"\n}, new OpenAIEmbedder());\n\n// Adicionar múltiplos vector stores\nawait agent.addVectorStore('technical-docs', {\n  type: 'chroma',\n  url: 'http://localhost:8000',\n  indexName: 'technical-documents',\n  dimension: 1536\n});\n\nawait agent.addVectorStore('business-knowledge', {\n  type: 'pinecone',\n  apiKey: process.env.PINECONE_API_KEY,\n  indexName: 'business-insights',\n  dimension: 1536\n});\n\n// Usar conhecimento de todas as fontes\nconst response = await agent.sendKnowledgeAugmentedMessage(\n  'Como implementar uma solução de IA em minha empresa?'\n);\nconsole.log('Resposta com conhecimento integrado:', response);\n```\n\n## Considerações de Implementação\n\n### 1. Embeddings\n- Escolha de modelo de embedding apropriado\n- Normalização de embeddings\n- Caching de embeddings frequentes\n\n### 2. Performance\n- Batch processing para indexação\n- Pooling de conexões\n- Caching de resultados de busca\n\n### 3. Escalabilidade\n- Sharding de índices\n- Balanceamento de carga\n- Monitoramento de uso de recursos\n\n### 4. Segurança\n- Validação de dados de entrada\n- Controle de acesso a índices\n- Criptografia de dados sensíveis\n\n## Próximos Passos\n\n1. Implementar protótipo do PineconeVectorStore\n2. Criar ChromaVectorStore\n3. Desenvolver mecanismo de embedding (OpenAI, HuggingFace, etc.)\n4. Testar cenários de RAG com agentes\n5. Adicionar suporte a outros vector stores (Weaviate, Qdrant)\n6. Implementar caching de embeddings e resultados\n7. Documentar padrões de uso e boas práticas